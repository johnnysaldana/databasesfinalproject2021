{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "658d90ac-29b6-41a3-8d40-e9600880762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull stock data using Alpha Vantage\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import AV_Errors\n",
    "\n",
    "API_URL = \"https://www.alphavantage.co/query\"\n",
    "\n",
    "API_KEY = \"VK80229IJIZZ6BV3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "598723d4-5b84-4eb4-996d-e7f3ec26cf42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata = {\"function\": \"TIME_SERIES_MONTHLY\",\\n        \"symbol\": \"MSFT\",\\n        \"datatype\": \"json\",\\n        \"outputsize\": \"full\",\\n        \"apikey\": userInfo.key_gen()}\\n\\nprint(\"###################################################################\")\\nresponse = requests.get(API_URL, data, proxies={\\n                        \"http\": \"212.30.52.37:42939\", \"https\": \"212.30.52.37:42939\"}, timeout=1)\\n\\nprint(response)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull stock data using Alpha Vantage\n",
    "\n",
    "def time_series(function, adj):\n",
    "    time_series_string = \"\"\n",
    "\n",
    "    if adj and function == \"DAILY\":\n",
    "        time_series_string = \"Time Series (Daily)\"\n",
    "\n",
    "    elif adj:\n",
    "        series = \" Adjusted Time Series\"\n",
    "        time_series_string = function[0] + function[1:].lower() + series\n",
    "\n",
    "    elif function.upper() == \"DAILY\":\n",
    "        time_series_string = \"Time Series (Daily)\"\n",
    "\n",
    "    else:\n",
    "        time_series_string = function[0] + function[1:].lower() + \" Time Series\"\n",
    "\n",
    "    return time_series_string\n",
    "\n",
    "\n",
    "def format_df(function, df, symbol, adj):\n",
    "    if function == \"DAILY\" and adj:\n",
    "        col_extra1 = [\"adjusted close\"]\n",
    "        col_extra2 = [\"dividend amount\", \"split coefficient\"]\n",
    "    elif adj:\n",
    "        col_extra1 = [\"adjusted close\"]\n",
    "        col_extra2 = [\"dividend amount\"]\n",
    "    else:\n",
    "        col_extra1 = []\n",
    "        col_extra2 = []\n",
    "\n",
    "    df.columns = [\"open\", \"high\", \"low\", \"close\"] + col_extra1 + [\"volume\"] + col_extra2\n",
    "    df[\"meta\"] = \"\"\n",
    "    df.insert(0, \"date\", df.index)\n",
    "\n",
    "    df = df.reindex(index=df.index[::-1])\n",
    "    date = str(datetime.now())\n",
    "    df[\"meta\"][0] = [['src', 'Alpha Vantage'],\n",
    "                     ['date', date],\n",
    "                     ['symb', symbol],\n",
    "                     ['function', function.lower() + (\"adj\" if adj else \"\")],\n",
    "                     ['resolution', 'n/a'],\n",
    "                     ['start', str(df.tail(1)[\"date\"]).split()[0]],\n",
    "                     ['end', str(df.head(1)[\"date\"]).split()[0]],\n",
    "                     ['length', str(len(df))]]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_historical(function, symbol, ip=\"default\"):\n",
    "    if function not in [\"MONTHLY\", \"DAILY\", \"WEEKLY\"]:\n",
    "        raise Exception(\"Invalid value: '\" + function + \"' \\n\"\n",
    "                        \" Acceptable values are: 'MONTHLY', 'WEEKLY', \" +\n",
    "                        \"'DAILY'\")\n",
    "\n",
    "    data = {\"function\": \"TIME_SERIES_\" + function.upper(),\n",
    "            \"symbol\": symbol,\n",
    "            \"datatype\": \"json\",\n",
    "            \"outputsize\": \"full\",\n",
    "            \"apikey\": API_KEY}\n",
    "\n",
    "    data = AV_Errors.request_err_production(API_URL, data, ip)\n",
    "\n",
    "    AV_Errors.df_key_err_production(data, symbol)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data[time_series(function,\n",
    "                                                 False)]).transpose()\n",
    "\n",
    "    return format_df(function, df, symbol, False)\n",
    "\n",
    "\n",
    "def get_historical_adjusted(function, symbol, ip=\"default\"):\n",
    "    if function not in [\"MONTHLY\", \"DAILY\", \"WEEKLY\"]:\n",
    "        raise Exception(\"Invalid value: '\" + function + \"' \\n\"\n",
    "                        \" Acceptable values are: 'MONTHLY', 'WEEKLY', 'DAILY'\")\n",
    "\n",
    "    data = {\"function\": \"TIME_SERIES_\" + function.upper() + \"_ADJUSTED\",\n",
    "            \"symbol\": symbol,\n",
    "            \"datatype\": \"json\",\n",
    "            \"outputsize\": \"full\",\n",
    "            \"apikey\": API_KEY}\n",
    "\n",
    "    data = AV_Errors.request_err_production(API_URL, data, ip)\n",
    "\n",
    "    AV_Errors.df_key_err_production(data, symbol)\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data[time_series(function,\n",
    "                                                 True)]).transpose()\n",
    "\n",
    "    return format_df(function, df, symbol, True)\n",
    "\n",
    "\n",
    "def get_sector_perf():\n",
    "    data = {\"function\": \"SECTOR\",\n",
    "            \"apikey\": API_KEY}\n",
    "\n",
    "    data = AV_Errors.request_err_production(API_URL, data)\n",
    "\n",
    "    key_lst = []\n",
    "    val_lst = []\n",
    "\n",
    "    for key in list(keys)[1:]:\n",
    "        val_lst.append(data[key])\n",
    "        key_lst.append(key.split(\":\")[1][1:])\n",
    "    df = pd.DataFrame()\n",
    "    df[\"sector period\"] = key_lst\n",
    "\n",
    "    real_est = []\n",
    "    energy = []\n",
    "    utilities = []\n",
    "    financials = []\n",
    "    staples = []\n",
    "    health_care = []\n",
    "    industrials = []\n",
    "    materials = []\n",
    "    IT = []\n",
    "    consumer_discr = []\n",
    "    x = []\n",
    "    communic_serv = []\n",
    "\n",
    "    for key in list(data.keys())[1:]:\n",
    "        real_est.append(data[key][\"Real Estate\"] if \"Real Estate\" in data[key]\n",
    "                        else \"\")\n",
    "        energy.append(data[key][\"Energy\"])\n",
    "        utilities.append(data[key][\"Utilities\"])\n",
    "        financials.append(data[key][\"Financials\"])\n",
    "        staples.append(data[key][\"Consumer Staples\"])\n",
    "        health_care.append(data[key][\"Health Care\"])\n",
    "        industrials.append(data[key][\"Industrials\"])\n",
    "        materials.append(data[key][\"Materials\"])\n",
    "        IT.append(data[key][\"Information Technology\"])\n",
    "        consumer_discr.append(data[key][\"Consumer Discretionary\"])\n",
    "        communic_serv.append(data[key][\"Communication Services\"])\n",
    "\n",
    "    df[\"Real Estate\"] = real_est\n",
    "    df[\"Energy\"] = energy\n",
    "    df[\"Utilities\"] = utilities\n",
    "    df[\"Financials\"] = financials\n",
    "    df[\"Consumer Staples\"] = staples\n",
    "    df[\"Health Care\"] = health_care\n",
    "    df[\"Industrials\"] = industrials\n",
    "    df[\"Materials\"] = materials\n",
    "    df[\"Information Technology\"] = IT\n",
    "    df[\"Communication Services\"] = consumer_discr\n",
    "    df[\"Materials\"] = communic_serv\n",
    "\n",
    "    df = df.reindex(index=df.index[::-1])\n",
    "    return df\n",
    "\n",
    "\n",
    "'''\n",
    "data = {\"function\": \"TIME_SERIES_MONTHLY\",\n",
    "        \"symbol\": \"MSFT\",\n",
    "        \"datatype\": \"json\",\n",
    "        \"outputsize\": \"full\",\n",
    "        \"apikey\": userInfo.key_gen()}\n",
    "\n",
    "print(\"###################################################################\")\n",
    "response = requests.get(API_URL, data, proxies={\n",
    "                        \"http\": \"212.30.52.37:42939\", \"https\": \"212.30.52.37:42939\"}, timeout=1)\n",
    "\n",
    "print(response)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14e041d9-49b4-4592-8616-c7c28eb25f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.1-cp39-cp39-macosx_10_13_x86_64.whl (8.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.0 MB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.0.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.20.2)\n",
      "Collecting scipy>=1.1.0\n",
      "  Downloading scipy-1.7.3-cp39-cp39-macosx_10_9_x86_64.whl (33.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 33.2 MB 5.6 MB/s eta 0:00:012\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[K     |████████████████████████████████| 306 kB 4.7 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=109301d663e99b43e49e56e54a69bf017cb9657e778fabc9b4a0987ed758b908\n",
      "  Stored in directory: /Users/j/Library/Caches/pip/wheels/e4/7b/98/b6466d71b8d738a0c547008b9eb39bf8676d1ff6ca4b22af1c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-1.1.0 scikit-learn-1.0.1 scipy-1.7.3 sklearn-0.0 threadpoolctl-3.0.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e7f2e36-551f-455b-9570-748226d3a1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # *get_stock_data*\n",
    "# \n",
    "# Utility functions to download and retrieve stock data and then quickly retrieve it from the created database\n",
    "# \n",
    "# \n",
    "\n",
    "# In[81]:\n",
    "\n",
    "\n",
    "# Packages\n",
    "\n",
    "# Package Imports\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_datareader as pddr # Returns historical stock information: pip install pandas-datareader\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from mpl_finance import candlestick_ohlc # Extends matplot for financial plotting: pip install mpl-finance \n",
    "from datetime import datetime\n",
    "from sklearn import preprocessing # used for normalizing data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ROOT = '/Users/j/Desktop/research/'\n",
    "\n",
    "\n",
    "# In[86]:\n",
    "\n",
    "\n",
    "def return_differences(graph, axis=0):\n",
    "    # returns a list of the differences between each point in the graph\n",
    "    l = []\n",
    "    g = sorted(graph)\n",
    "    for i in range(len(g)-1):\n",
    "        l.append(g[i+1][axis] - g[i][axis])\n",
    "    \n",
    "    return l\n",
    "        \n",
    "\n",
    "\n",
    "# In[87]:\n",
    "\n",
    "\n",
    "def log_changes(y_values, start_price=-1):\n",
    "    \"\"\"\"Returns the log changes for a list of y values.\n",
    "\n",
    "    Args:\n",
    "        y_values (List): The list of ordered y values from the fractal graph.\n",
    "        start_price (int): Useful if stock starts at certain price.\n",
    "\n",
    "    Returns:\n",
    "        DataDrame: Returns a dataframe with the log returns.\n",
    "    \"\"\"\n",
    "    if start_price == -1:\n",
    "        start_price = abs(min(y_values)) + 1\n",
    "    \n",
    "    fixed = [x+start_price for x in y_values]\n",
    "    df = pd.DataFrame(fixed, columns=['price'])\n",
    "    df['pct_change'] = df.price.pct_change()\n",
    "    df['log_ret'] = np.log(df.price) - np.log(df.price.shift(1))\n",
    "    return df['log_ret']\n",
    "\n",
    "\n",
    "# In[88]:\n",
    "\n",
    "\n",
    "def plot_data_list(data, column='Normalized Close', save=False):\n",
    "    fig, ax = plt.subplots() # Needs to go before everything else\n",
    "    tickers = []\n",
    "    #values = []\n",
    "    for key in data.keys():\n",
    "        tickers.append(key)\n",
    "        #values.append(data[key][column])\n",
    "        stock = data[key]\n",
    "        ax.plot(stock['Date'], list(stock[column]))\n",
    "    \n",
    "    \n",
    "    plt.legend(tickers,loc='best')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(column)\n",
    "    plt.title(tickers[0] + ', ' + ', '.join(tickers[1:])+ ' ' + column)\n",
    "    \n",
    "    # round to nearest years.\n",
    "    #datemin = np.datetime64(data['date'][0], 'Y')\n",
    "    #datemax = np.datetime64(data['date'][-1], 'Y') + np.timedelta64(1, 'Y')\n",
    "    #ax.set_xlim(datemin, datemax)\n",
    "\n",
    "    # format the coords message box\n",
    "    #ax.format_xdata = mdates.DateFormatter('%Y-%m-%d')\n",
    "\n",
    "    \n",
    "    plt.grid(color='k', linestyle='-', linewidth=0.1)\n",
    "    plt.tick_params(axis='x', which='major', labelsize=10)\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=1))\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.gcf().set_size_inches(30,4)\n",
    "    #matplotlib.rcParams['figure.dpi'] = 200\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "# In[89]:\n",
    "\n",
    "\n",
    "def add_normalized_close(df):\n",
    "    # Create x, where x the 'scores' column's values as floats\n",
    "    x = df[['Adj Close']].values.astype(float)\n",
    "\n",
    "    # Create a minimum and maximum processor object\n",
    "    min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "    # Create an object to transform the data to fit minmax processor\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "    # Run the normalizer on the dataframe\n",
    "    df['Normalized Close'] = x_scaled\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_existing_tickers():\n",
    "    lst = []\n",
    "    basepath = ROOT + 'Daily'\n",
    "    for entry in os.listdir(basepath):\n",
    "        if os.path.isfile(os.path.join(basepath, entry)):\n",
    "            lst.append(entry)\n",
    "            \n",
    "    return lst\n",
    "    \n",
    "                 \n",
    "            \n",
    "def resource_data_list(lst, start='2010-1-1', end='2020-1-1',overwrite=False):\n",
    "    data = {}\n",
    "    \n",
    "    existing_tickers = get_existing_tickers()\n",
    "    \n",
    "    for ticker in lst:\n",
    "        try:\n",
    "            if ticker + '.csv' in existing_tickers and not(overwrite):\n",
    "                data[ticker] = pd.read_csv(ROOT + 'Daily/' + ticker + '.csv')\n",
    "\n",
    "            else:\n",
    "                stock = pddr.DataReader(ticker, \n",
    "                               start=start, \n",
    "                               end = end,\n",
    "                               data_source='yahoo')\n",
    "\n",
    "                stock = add_normalized_close(stock)\n",
    "                data[ticker] = stock\n",
    "\n",
    "                stock.to_csv(ROOT + 'Daily/' + ticker + '.csv' )\n",
    "        except Exception as e:\n",
    "            print(\"Error: \", ticker, e)\n",
    "            \n",
    "            \n",
    "        \n",
    "    return data\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e45e6b-a55b-4124-9960-1c864ab709df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=resource_data_list([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a9b8f99-9b5a-42b9-a49e-f985b55998bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_historical(\"MONTHLY\", \"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e1db2b7-a00a-43f0-b051-dc5bd983a080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999-12-31</th>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>101.0000</td>\n",
       "      <td>118.0000</td>\n",
       "      <td>91.0600</td>\n",
       "      <td>102.8100</td>\n",
       "      <td>84091200</td>\n",
       "      <td>[[src, Alpha Vantage], [date, 2021-12-19 12:10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>2000-01-31</td>\n",
       "      <td>104.8700</td>\n",
       "      <td>121.5000</td>\n",
       "      <td>86.5000</td>\n",
       "      <td>103.7500</td>\n",
       "      <td>112099800</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-29</th>\n",
       "      <td>2000-02-29</td>\n",
       "      <td>104.0000</td>\n",
       "      <td>119.9400</td>\n",
       "      <td>97.0000</td>\n",
       "      <td>114.6200</td>\n",
       "      <td>65355200</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-31</th>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>118.5600</td>\n",
       "      <td>150.3800</td>\n",
       "      <td>114.0000</td>\n",
       "      <td>135.8100</td>\n",
       "      <td>77663900</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-28</th>\n",
       "      <td>2000-04-28</td>\n",
       "      <td>135.5000</td>\n",
       "      <td>139.5000</td>\n",
       "      <td>104.8700</td>\n",
       "      <td>124.0600</td>\n",
       "      <td>77342900</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-08-31</th>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>146.3600</td>\n",
       "      <td>153.4900</td>\n",
       "      <td>144.5000</td>\n",
       "      <td>151.8300</td>\n",
       "      <td>1462773381</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-09-30</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>152.8300</td>\n",
       "      <td>157.2600</td>\n",
       "      <td>141.2700</td>\n",
       "      <td>141.5000</td>\n",
       "      <td>1797948421</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-29</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>141.9000</td>\n",
       "      <td>153.1650</td>\n",
       "      <td>138.2700</td>\n",
       "      <td>149.8000</td>\n",
       "      <td>1565079040</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30</th>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>148.9850</td>\n",
       "      <td>165.7000</td>\n",
       "      <td>147.4800</td>\n",
       "      <td>165.3000</td>\n",
       "      <td>1688864233</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-17</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>167.4800</td>\n",
       "      <td>182.1300</td>\n",
       "      <td>157.8000</td>\n",
       "      <td>171.1400</td>\n",
       "      <td>1746202940</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>265 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date      open      high       low     close      volume  \\\n",
       "1999-12-31  1999-12-31  101.0000  118.0000   91.0600  102.8100    84091200   \n",
       "2000-01-31  2000-01-31  104.8700  121.5000   86.5000  103.7500   112099800   \n",
       "2000-02-29  2000-02-29  104.0000  119.9400   97.0000  114.6200    65355200   \n",
       "2000-03-31  2000-03-31  118.5600  150.3800  114.0000  135.8100    77663900   \n",
       "2000-04-28  2000-04-28  135.5000  139.5000  104.8700  124.0600    77342900   \n",
       "...                ...       ...       ...       ...       ...         ...   \n",
       "2021-08-31  2021-08-31  146.3600  153.4900  144.5000  151.8300  1462773381   \n",
       "2021-09-30  2021-09-30  152.8300  157.2600  141.2700  141.5000  1797948421   \n",
       "2021-10-29  2021-10-29  141.9000  153.1650  138.2700  149.8000  1565079040   \n",
       "2021-11-30  2021-11-30  148.9850  165.7000  147.4800  165.3000  1688864233   \n",
       "2021-12-17  2021-12-17  167.4800  182.1300  157.8000  171.1400  1746202940   \n",
       "\n",
       "                                                         meta  \n",
       "1999-12-31  [[src, Alpha Vantage], [date, 2021-12-19 12:10...  \n",
       "2000-01-31                                                     \n",
       "2000-02-29                                                     \n",
       "2000-03-31                                                     \n",
       "2000-04-28                                                     \n",
       "...                                                       ...  \n",
       "2021-08-31                                                     \n",
       "2021-09-30                                                     \n",
       "2021-10-29                                                     \n",
       "2021-11-30                                                     \n",
       "2021-12-17                                                     \n",
       "\n",
       "[265 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585dc72-c861-4788-88f0-de2881d8a9db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
